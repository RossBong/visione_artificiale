{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297a9767-b39e-4796-897b-6d30aabc5af9",
   "metadata": {},
   "source": [
    "# Assignment 2 Visione Artificiale,          Rosario Bongiorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2293fe-9964-4794-9553-848f81eb7a22",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2025dea-2181-4fcc-b3c1-11ec4a5c083a",
   "metadata": {},
   "source": [
    "Inizialmente importo i pacchetti e definisco le prime funzioni che serviranno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "829fb66f-ece3-4449-a40e-bbb091fe9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def ViolaJones(percorso):\n",
    "    img = cv2.imread(percorso)\n",
    "    faces_xml = 'haarcascade_frontalface_alt.xml'\n",
    "    face_cascade = cv2.CascadeClassifier()\n",
    "    # -- 1. Load the cascades\n",
    "    if not face_cascade.load(faces_xml):\n",
    "        print('--(!)Error loading face cascade')\n",
    "        exit(0)\n",
    "    \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_vj = face_cascade.detectMultiScale(img)\n",
    "    volto=np.zeros(4096, dtype=np.float32)\n",
    "    for (x, y, w, h) in img_vj:\n",
    "        faceROI = img[y:y + h, x:x + w]\n",
    "        volto=cv2.resize(faceROI, (64,64)).flatten()\n",
    " \n",
    "    return volto\n",
    "\n",
    "def project(gallery,mean,u):\n",
    "    a=np.zeros((np.shape(gallery)[0],np.shape(u)[0]), dtype=np.float32)\n",
    "    i=0\n",
    "    for img in gallery:\n",
    "        diff=img-mean\n",
    "        a[i]=np.dot(diff,u.T)\n",
    "        i=i+1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936730d3-23fe-4a74-a32e-442d4c4a5108",
   "metadata": {},
   "source": [
    "Procedo importando il dataset “All images aligned with funneling”, seleziono esclusvamente 2000 foto e ne calcolo la matrice media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4031e82-31cb-4c00-931f-16b848f4035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c=0\n",
    "face=np.zeros((2000,4096), dtype=np.float32)\n",
    "sum=np.zeros((64,64), dtype=np.float32)\n",
    "for cartella, sottocartelle, files in os.walk(\"./lfw_funneled\"):\n",
    "    for file in files:\n",
    "        if c>=2000:\n",
    "            break\n",
    "        if file.endswith(\".jpg\"):\n",
    "           \n",
    "            img_vect = ViolaJones(cartella+\"/\"+file)\n",
    "            face[c]=img_vect\n",
    "            c=c+1\n",
    "       \n",
    "\n",
    "\n",
    "mean_vect=np.mean(face,axis=0)\n",
    "mean=np.reshape(mean_vect, (64,64))\n",
    "mean=mean.astype(np.uint8)\n",
    "\n",
    "file = open('data/mean_vect', 'wb')\n",
    "pickle.dump(mean_vect, file)\n",
    "file.close()\n",
    "\n",
    "cv2.imshow('img_media',mean)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b37f0-78a6-4bf1-8704-e3766b253223",
   "metadata": {},
   "source": [
    "Calcolo la matrice di covarianza, successivamente applico SVD, così da ottenere le gli autovettori che rappresentano i nostri egeinfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee1705e4-2cef-48f5-958f-1ba1df7fcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "for i in range(2000):\n",
    "    face[i]=face[i]-mean_vect\n",
    "    \n",
    "C=np.cov(np.transpose(face))\n",
    "\n",
    "#applico svd\n",
    "u, s, vh = np.linalg.svd(C, full_matrices=True)\n",
    "scaler = MinMaxScaler(feature_range=(0,255))\n",
    "u = scaler.fit_transform(np.transpose(u))#eigenfaces\n",
    "\n",
    "file = open('data/u', 'wb')\n",
    "pickle.dump(u, file)\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9517f0-8e12-4086-acd9-6d08c41100e7",
   "metadata": {},
   "source": [
    "Calcolo il numero di eigenfaces che mi serviranno per avere una varianza del 95% e del 99,99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "504cdf06-14f3-43bb-8ea3-601ce1508fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di eigenfaces necessari per una varianza del 95%: 4\n",
      "Numero di eigenfaces necessari per una varianza del 99,99%: 140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s=((s-s.min())/(s.max()-s.min()))\n",
    "variance_sum = np.cumsum(s**2)\n",
    "total_variance = np.sum(s**2)\n",
    "cumulative_variance_ratio = variance_sum / total_variance\n",
    "\n",
    "\n",
    "eig_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
    "print(\"Numero di eigenfaces necessari per una varianza del 95%:\", eig_95)\n",
    "    \n",
    "eig_99= np.argmax(cumulative_variance_ratio >= 0.9999) + 1\n",
    "print(\"Numero di eigenfaces necessari per una varianza del 99,99%:\", eig_99)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e79cc-e85d-4f96-a79f-71bd768e1521",
   "metadata": {},
   "source": [
    "Carico le immagini della gallery dei volti, applico Viola Jones e li salvo insieme alle rispettive etichette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0363edb8-c3e7-496c-8640-6e4e6fcb1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "gallery_img=np.zeros((48,4096), dtype=np.float32)\n",
    "gallery_label=[]\n",
    "\n",
    "for cartella, sottocartelle, files in os.walk(\"./gallery\"):\n",
    "    for file in files:\n",
    "        \n",
    "        if file.endswith(\".png\"):\n",
    "            img_vect = ViolaJones(cartella+\"/\"+file)\n",
    "            gallery_img[i]=img_vect\n",
    "            gallery_label.append(re.sub('_[0-9]+.png', '', file))\n",
    "            i=i+1\n",
    "            \n",
    "file = open('data/gallery_img', 'wb')\n",
    "pickle.dump(gallery_img, file)\n",
    "file.close()\n",
    "\n",
    "file = open('data/gallery_label', 'wb')\n",
    "pickle.dump(gallery_label, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975c849-232d-45d4-8b8a-3673f20824e2",
   "metadata": {},
   "source": [
    "Estrapolo dal video effettuato in laboratorio i 20 frame che utilizzerò per il validation set.\n",
    "\n",
    "NB. non eseguire questo codice altrimenti la label non corrisponderà con il validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb63284-507c-4dc4-97b6-9fedb2fbc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture('./gallery/validation.mp4')\n",
    "validation=[]\n",
    "# Leggi i primi 20 frame del video\n",
    "for i in range(60):\n",
    "    \n",
    "    if i%3==0:\n",
    "        ret, test_img = cap.read()\n",
    "        # Se la lettura del frame ha avuto successo\n",
    "        if ret:\n",
    "            test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces_xml = 'haarcascade_frontalface_alt.xml'\n",
    "            face_cascade = cv2.CascadeClassifier()\n",
    "                # -- 1. Load the cascades\n",
    "            if not face_cascade.load(faces_xml):\n",
    "                    print('--(!)Error loading face cascade')\n",
    "                    exit(0)\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(test_img)\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = test_img[y:y+h, x:x+w]\n",
    "                test_feature = cv2.resize(roi, (64, 64)).flatten()\n",
    "                validation.append(test_feature)\n",
    "validationset=np.array(validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2681b-0025-4b2c-89b4-abdb3262be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/validation', 'wb')\n",
    "pickle.dump(validation, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f849e4-a6f4-4c52-9285-b2319e700da2",
   "metadata": {},
   "source": [
    "Creo La label del validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30d59598-dbca-4a05-85d4-452235ed2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val=['antonio','rosario','n','daniele','alessandro','antonio','rosario','n','alessandro','daniele','antonio','rosario','n',\n",
    "           'alessandro','daniele','antonio','rosario','n','alessandro','daniele','antonio','rosario','n','alessandro','daniele','rosario','antonio',\n",
    "           'alessandro','daniele','antonio','rosario','daniele','alessandro','antonio','rosario','alessandro','daniele','n','antonio',\n",
    "           'rosario','alessandro','daniele','n','antonio','rosario','daniele','alessandro','antonio','rosario','alessandro','daniele','antonio',\n",
    "           'daniele','alessandro','antonio','alessandro','daniele','antonio','alessandro','daniele','antonio','daniele','alessandro',\n",
    "           'antonio','alessandro','daniele','antonio','alessandro','daniele','antonio','daniele','alessandro','antonio','daniele','alessandro',\n",
    "           'antonio','alessandro','daniele']\n",
    "label_val=np.array(label_val)\n",
    "\n",
    "file = open('data/label_val', 'wb')\n",
    "pickle.dump(label_val, file)\n",
    "file.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac4eef-cfc9-463d-ad31-8b2a4cc9573a",
   "metadata": {},
   "source": [
    "Per una visualizzazione più immediata dei dati eseguire il sequente blocco di codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3882120-4643-41f7-90c8-d4d3f47342b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/validation', 'rb')                           \n",
    "validation= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "file = open('data/label_val', 'rb')                           \n",
    "label_val= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "file = open('data/gallery_img', 'rb')                           \n",
    "gallery_img= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "file = open('data/gallery_label', 'rb')                           \n",
    "gallery_label= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "file = open('data/u', 'rb')                           \n",
    "u= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "file = open('data/mean_vect', 'rb')                           \n",
    "mean_vect= pickle.load(file)              \n",
    "file.close()\n",
    "\n",
    "\n",
    "validation=np.delete(validation,[2,7,12,17,22,37,42],0)#elimino le immagini che non rappresentano dei volti\n",
    "label_val=np.delete(label_val,[2,7,12,17,22,37,42])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5a353-683e-4359-b4ad-b7c8b66a2b20",
   "metadata": {},
   "source": [
    "Creo un classificatore KNN che addestro con il training set derivato dalla gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db723063-599f-45ef-9a1c-93c029c45b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza con varianza:95% e k:1---------------->0.28169014084507044\n",
      "Accuratezza con varianza:95% e k:3---------------->0.28169014084507044\n",
      "Accuratezza con varianza:95% e k:5---------------->0.28169014084507044\n",
      "Accuratezza con varianza:99,99% e k:1---------------->0.30985915492957744\n",
      "Accuratezza con varianza:99,99% e k:3---------------->0.28169014084507044\n",
      "Accuratezza con varianza:99,99% e k:5---------------->0.28169014084507044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for num_eig in [5,140]:\n",
    "    for k in [1,3,5]:\n",
    "        \n",
    "        #proietto i dati della gallery nello spazio delle eigenfaces\n",
    "        a_training=project(gallery_img,mean_vect,u[:num_eig,])\n",
    "        #proietto i dati del validation set nello spazio delle eigenfaces\n",
    "        a_validation=project(validation,mean_vect,u[:num_eig,])\n",
    "        \n",
    "        \n",
    "        # Crea il classificatore KNN\n",
    "        knn = KNN(n_neighbors=k)\n",
    "        #addestro il classificatore con il training set e le rispettive label\n",
    "        knn.fit(a_training, gallery_label)\n",
    "        #predico i risultati\n",
    "        label = knn.predict(a_validation)\n",
    "        #tamite il validation set ottengo una stima del mio classificatore\n",
    "        accuratezza=knn.score(a_validation,label_val)\n",
    "        if num_eig==5:\n",
    "            var=\"95%\"\n",
    "        else:\n",
    "            var=\"99,99%\"\n",
    "        print(\"Accuratezza con varianza:\"+var+\" e k:\"+str(k)+\"---------------->\"+str(accuratezza))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5285a9-5c94-4d3f-9feb-8fa028001152",
   "metadata": {},
   "source": [
    "Dai risultati ottenuti, la miglior combinazione è varianza al 99,99% e k=1, quindi effettuo il test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26555fa0-386d-465c-985e-a4601c1111e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_training=project(gallery_img,mean_vect,u[:140,])\n",
    "a_validation=project(validation,mean_vect,u[:140,])\n",
    "        \n",
    "        \n",
    "        # Crea il classificatore KNN\n",
    "knn = KNN(n_neighbors=1)\n",
    "knn.fit(a_training, gallery_label)\n",
    "\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Apri il video\n",
    "cap = cv2.VideoCapture('./gallery/test_1.mp4')\n",
    "\n",
    "# Loop attraverso ogni frame del video\n",
    "while True:\n",
    "    # Leggi un frame dal video\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Applica l'algoritmo di Viola-Jones per rilevare le facce nel frame\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    for (x, y, w, h) in faces:\n",
    "        faceROI = gray[y:y + h, x:x + w]\n",
    "        test_feature=cv2.resize(faceROI, (64,64)).flatten()\n",
    "        test_feature=project(np.array([test_feature]),mean_vect,u[:140,])\n",
    "        label = knn.predict(test_feature)\n",
    "        cv2.putText(frame, f\"{label}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Se viene premuto il tasto 'q' interrompi il loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da96e5-199f-4080-a0dd-43c916aaea07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
